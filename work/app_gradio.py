#!/usr/bin/env python3
"""
UNBOXED â€” Interface Gradio pour le pipeline radiologique agentique.
Hackathon GE Healthcare x Centrale Lyon 2026.

Usage:
    python app_gradio.py
"""

import json
import os
import sys
import time
import traceback
from pathlib import Path

import gradio as gr
import pandas as pd
import plotly.graph_objects as go

# â”€â”€ Setup paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SCRIPT_DIR = Path(__file__).parent.resolve()
BASE_DIR = SCRIPT_DIR.parent
EXCEL_PATH = BASE_DIR / "Liste examen UNBOXED finaliseÄ£e v2 (avec mesures).xlsx"
PATIENTS_DIR = SCRIPT_DIR / "patients"

# Add work/ to path for pipeline imports
sys.path.insert(0, str(SCRIPT_DIR))

from pipeline import (
    load_gemini_key,
    get_orthanc_session,
    step_discovery,
    step_download,
    step_segmentation,
    step_analyse_seg,
    step_clinical_context,
    classify_findings,
    build_lesion_tracking_table,
    build_recist_evaluation,
    extract_exam_motif,
    compute_confidence,
    compute_all_vdt,
    format_vdt_text,
    format_recist_reasoning,
    format_lungrads_reasoning,
    analyze_hounsfield,
    audit_data_completeness,
    format_tagged_data,
    build_sources_trace,
    step_generate_report,
    verify_report,
    build_correction_prompt,
    call_gemini_correction,
    evaluate_report_quality,
    step_output,
    classify_clinical_context,
)
import pydicom


# â”€â”€ Load patients from Excel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_patient_choices():
    """Build dropdown choices â€” only accessions with local DICOM data or results."""
    if not EXCEL_PATH.exists():
        return ["Excel non trouvÃ© â€” vÃ©rifiez le chemin"]
    df = pd.read_excel(str(EXCEL_PATH))

    # Check Orthanc availability once
    orthanc_ok = False
    try:
        get_orthanc_session()
        orthanc_ok = True
    except Exception:
        pass

    choices = []
    for pid, group in df.groupby("PatientID"):
        accs = sorted(group["AccessionNumber"].astype(str).tolist())
        n = len(accs)
        all_text = " ".join(str(v) for v in group["Clinical information data (Pseudo reports)"].values).lower()
        scenario = "B (RECIST)" if any(kw in all_text for kw in ["neoplasia", "clinical trial", "oncolog", "carcinoma", "metast"]) else "A (Lung-RADS)"

        added = False
        for acc in accs:
            has_dicom = (PATIENTS_DIR / acc / "original").exists() and any((PATIENTS_DIR / acc / "original").glob("*.dcm"))
            has_report = (PATIENTS_DIR / acc / "rapport_radiologique.md").exists()
            if has_dicom or has_report:
                tag = " âœ… Rapport prÃªt" if has_report else " ğŸ“‚ DICOM local"
                choices.append(f"{pid} | Acc {acc} | {n} exams | {scenario} |{tag}")
                added = True

        if not added and orthanc_ok:
            # Only show patients needing Orthanc if Orthanc is reachable
            choices.append(f"{pid} | Acc {accs[0]} | {n} exams | {scenario} | ğŸŒ Orthanc requis")

    if not choices:
        return ["Aucun patient disponible (pas de donnÃ©es locales, Orthanc inaccessible)"]

    return choices


def parse_selection(selection: str):
    """Extract patient_id and accession from dropdown selection."""
    if not selection or "|" not in selection:
        return None, None
    parts = selection.split("|")
    patient_id = parts[0].strip()
    acc_part = parts[1].strip()  # "Acc 10969511"
    accession = acc_part.replace("Acc ", "").strip()
    return patient_id, accession


# â”€â”€ Load existing results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_existing_results(selection):
    """Load already-generated results without running the pipeline."""
    _, accession = parse_selection(selection)
    if not accession:
        return "SÃ©lectionnez un patient.", "", "", None

    patient_dir = PATIENTS_DIR / accession

    # Report
    report_path = patient_dir / "rapport_radiologique.md"
    if not report_path.exists():
        return (
            f"Aucun rÃ©sultat existant pour l'accession **{accession}**.\n\n"
            "Lancez le pipeline pour gÃ©nÃ©rer un rapport.",
            "", "", None,
        )
    report = report_path.read_text(encoding="utf-8")

    # Confidence card
    confidence_card = _build_confidence_card(patient_dir, accession)

    # Evolution chart
    chart = _build_evolution_chart(patient_dir)

    # Log
    log = f"RÃ©sultats chargÃ©s depuis le cache pour l'accession {accession}."

    return report, confidence_card, log, chart


def _build_confidence_card(patient_dir: Path, accession: str):
    """Build the confidence / verification markdown card."""
    lines = []

    # Patient summary
    summary_path = patient_dir / "patient_summary.json"
    if summary_path.exists():
        summary = json.loads(summary_path.read_text(encoding="utf-8"))
        ctx = summary.get("clinical_context", {})
        scenario = ctx.get("scenario", "?")
        scenario_name = ctx.get("scenario_name", "")
        criteria = ctx.get("criteria", "")
        evidence = ctx.get("evidence", [])

        lines.append("## ScÃ©nario clinique")
        icon = "ğŸ”¬" if scenario == "B" else "ğŸ«"
        lines.append(f"{icon} **ScÃ©nario {scenario}** â€” {scenario_name}")
        lines.append(f"CritÃ¨res : **{criteria}**")
        if evidence:
            lines.append(f"Evidence : {', '.join(evidence)}")
        lines.append("")

        # Confidence scores
        findings = summary.get("findings", [])
        if findings and findings[0].get("confidence"):
            lines.append("## Scores de confiance")
            for i, f in enumerate(findings, 1):
                conf = f.get("confidence", {})
                score = conf.get("score", "?")
                mx = conf.get("max", 8)
                level = conf.get("level", "?")
                cls = f.get("recist_classification", f.get("lungrads_classification", ""))
                d = f.get("diameter_axial_max_mm", 0)
                icon = "ğŸŸ¢" if score >= 6 else ("ğŸŸ¡" if score >= 3 else "ğŸ”´")
                lines.append(f"{icon} **F{i}** â€” {d:.1f}mm â€” {cls} â€” **{level} ({score}/{mx})**")
            lines.append("")

    # Verification report
    verif_path = patient_dir / "verification_report.json"
    if verif_path.exists():
        verif = json.loads(verif_path.read_text(encoding="utf-8"))
        lines.append("## VÃ©rification anti-hallucination")
        for check in verif.get("checks", []):
            status = check.get("status", "")
            item = check.get("item", "")
            if status == "OK":
                lines.append(f"âœ… {item}")
            elif "NON VÃ‰RIFIABLE" in status:
                lines.append(f"âš ï¸ {item} â€” {status}")
            else:
                lines.append(f"âŒ {item} â€” {status}")
        lines.append(f"\nğŸ“Š **Score de fiabilitÃ© : {verif.get('reliability_score', '?')}**")
        rec = verif.get("recommendation", "")
        if rec:
            lines.append(f"ğŸ’¡ {rec}")
        lines.append("")

    # Self-correction
    audit_path = patient_dir / "audit_trail.json"
    if audit_path.exists():
        audit = json.loads(audit_path.read_text(encoding="utf-8"))
        sc = audit.get("self_correction", {})
        if sc.get("applied"):
            orig = sc.get("original_issues", 0)
            corr = sc.get("corrected_issues", 0)
            fixed = orig - corr
            lines.append(f"ğŸ”„ **Self-correction appliquÃ©e** : {orig} â†’ {corr} problÃ¨mes ({fixed} corrigÃ©(s))")
        elif sc.get("original_issues", 0) > 0:
            lines.append("âš ï¸ Self-correction tentÃ©e mais rejetÃ©e")
        lines.append("")

    # Quality
    quality_path = patient_dir / "quality_report.json"
    if quality_path.exists():
        quality = json.loads(quality_path.read_text(encoding="utf-8"))
        lines.append("## QualitÃ© du rapport")
        score = quality.get("score", "?")
        lines.append(f"ğŸ“‹ **Score : {score}**")
        for check in quality.get("checks", []):
            icon = "âœ…" if check.get("status") == "OK" else "âŒ"
            lines.append(f"{icon} {check.get('item', '')}")
        lines.append("")

    return "\n".join(lines) if lines else "Aucune donnÃ©e de confiance disponible."


def _build_evolution_chart(patient_dir: Path):
    """Build a plotly chart showing lesion evolution."""
    summary_path = patient_dir / "patient_summary.json"
    if not summary_path.exists():
        return None

    # We need the tracking data. Try to reconstruct from Excel.
    summary = json.loads(summary_path.read_text(encoding="utf-8"))
    patient_id = summary.get("patient", {}).get("id", "")
    accession = summary.get("exam", {}).get("accession", "")

    if not EXCEL_PATH.exists() or not patient_id:
        return None

    df = pd.read_excel(str(EXCEL_PATH))
    patient_rows = df[df["PatientID"] == patient_id]
    if patient_rows.empty:
        return None

    # Parse lesion sizes per exam
    exams = []
    for _, row in patient_rows.iterrows():
        acc = str(row["AccessionNumber"])
        sizes_raw = str(row.get("lesion size in mm", ""))
        sizes = []
        for s in sizes_raw.strip().split("\n"):
            s = s.strip()
            if s:
                try:
                    sizes.append(float(s))
                except ValueError:
                    pass
        exams.append({"accession": acc, "sizes": sizes})

    # Sort: current exam last
    exams.sort(key=lambda e: (1 if e["accession"] == accession else 0, int(e["accession"])))

    if not exams:
        return None

    max_findings = max(len(e["sizes"]) for e in exams)
    exam_labels = [f"Exam {i+1}\n(acc {e['accession'][-4:]})" for i, e in enumerate(exams)]

    fig = go.Figure()
    colors = ["#ef4444", "#3b82f6", "#22c55e", "#f59e0b", "#8b5cf6", "#ec4899"]

    for fi in range(max_findings):
        y_vals = []
        for e in exams:
            if fi < len(e["sizes"]):
                y_vals.append(e["sizes"][fi])
            else:
                y_vals.append(None)
        fig.add_trace(go.Scatter(
            x=exam_labels,
            y=y_vals,
            mode="lines+markers",
            name=f"F{fi+1}",
            line=dict(color=colors[fi % len(colors)], width=3),
            marker=dict(size=10),
        ))

    fig.update_layout(
        title=dict(text=f"Ã‰volution des lÃ©sions â€” Patient {patient_id}", font=dict(size=16)),
        xaxis_title="Examen",
        yaxis_title="DiamÃ¨tre (mm)",
        template="plotly_white",
        height=400,
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
        margin=dict(l=40, r=20, t=60, b=40),
    )

    # Add 10mm threshold line for RECIST
    fig.add_hline(y=10, line_dash="dash", line_color="gray",
                  annotation_text="Seuil cible RECIST (10mm)",
                  annotation_position="bottom right")

    return fig


# â”€â”€ Run pipeline with progress â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_full_pipeline(selection, progress=gr.Progress()):
    """Run the full pipeline for a selected patient/accession."""
    _, accession = parse_selection(selection)
    if not accession:
        yield "SÃ©lectionnez un patient.", "", "", None
        return

    gemini_key = load_gemini_key(None)
    if not gemini_key:
        yield (
            "**Erreur** : ClÃ© Gemini non trouvÃ©e.\n\n"
            "Configurez `GEMINI_API_KEY` dans `./work/.env`.",
            "", "", None,
        )
        return

    log_lines = []

    def add_log(msg):
        log_lines.append(msg)
        return "\n".join(log_lines)

    patient_dir = PATIENTS_DIR / accession
    original_dir = patient_dir / "original"
    results_dir = PATIENTS_DIR / "_results"
    os.makedirs(str(original_dir), exist_ok=True)
    os.makedirs(str(results_dir), exist_ok=True)

    try:
        # Check if DICOM files already exist locally (skip Orthanc if so)
        existing_dcm = list(original_dir.glob("*.dcm")) if original_dir.exists() else []
        seg_result_dir = results_dir / accession
        existing_seg = list(seg_result_dir.glob("*.dcm")) if seg_result_dir.exists() else []

        if existing_dcm:
            # â”€â”€ Skip steps 1-2: reuse local files â”€â”€
            progress(0.05, desc="ğŸ“‚ Fichiers DICOM locaux dÃ©tectÃ©s...")
            n_slices = len(existing_dcm)
            log_text = add_log(f"ğŸ“‚ {n_slices} coupes DICOM dÃ©jÃ  prÃ©sentes â€” Orthanc non requis")
            yield "", "", log_text, None
        else:
            # â”€â”€ Step 1: Discovery â”€â”€
            progress(0.05, desc="ğŸ” Connexion Ã  Orthanc...")
            log_text = add_log("ğŸ” Connexion Ã  Orthanc...")
            yield "", "", log_text, None

            try:
                session, base_url = get_orthanc_session()
            except ConnectionError:
                log_text = add_log(
                    "âŒ Orthanc inaccessible et aucune donnÃ©e locale.\n"
                    "   VÃ©rifiez votre connexion rÃ©seau ou utilisez 'Voir rÃ©sultats existants'."
                )
                yield "**Erreur** : Orthanc inaccessible et pas de donnÃ©es locales pour cette accession.", "", log_text, None
                return

            study_id, series_id, patient_id = step_discovery(session, base_url, accession)
            log_text = add_log(f"âœ… Ã‰tude trouvÃ©e â€” PatientID: {patient_id}")
            yield "", "", log_text, None

            # â”€â”€ Step 2: Download â”€â”€
            progress(0.15, desc="ğŸ“¥ TÃ©lÃ©chargement CT...")
            log_text = add_log("ğŸ“¥ TÃ©lÃ©chargement des coupes CT...")
            yield "", "", log_text, None

            n_slices = step_download(session, base_url, series_id, str(original_dir))
            log_text = add_log(f"âœ… {n_slices} coupes tÃ©lÃ©chargÃ©es")
            yield "", "", log_text, None

        # â”€â”€ Step 3: Segmentation â”€â”€
        progress(0.25, desc="ğŸ§  Segmentation AI...")
        log_text = add_log("ğŸ§  Segmentation AI en cours...")
        yield "", "", log_text, None

        seg_path, info_text = step_segmentation(str(patient_dir), str(results_dir))
        log_text = add_log("âœ… Segmentation terminÃ©e")
        yield "", "", log_text, None

        # â”€â”€ Step 4: Analyse SEG â”€â”€
        progress(0.35, desc="ğŸ“Š Analyse volumÃ©trique...")
        log_text = add_log("ğŸ“Š Analyse volumÃ©trique des nodules...")
        yield "", "", log_text, None

        patient_info, exam_info, findings = step_analyse_seg(seg_path, str(original_dir))
        for f in findings:
            add_log(f"  â€¢ F{f['SegmentNumber']}: {f['diameter_axial_max_mm']:.1f}mm, {f['volume_mm3']:.0f}mmÂ³")
        log_text = add_log(f"âœ… {len(findings)} nodules analysÃ©s")
        yield "", "", log_text, None

        # â”€â”€ Step 5: Clinical context â”€â”€
        progress(0.45, desc="ğŸ“‹ Intelligence clinique...")
        log_text = add_log("ğŸ“‹ Chargement du contexte clinique...")
        yield "", "", log_text, None

        current_clinical, history_text, clinical_ctx, excel_df = step_clinical_context(patient_info["id"], accession)
        scenario = clinical_ctx["scenario"]
        log_text = add_log(f"âœ… ScÃ©nario {scenario} â€” {clinical_ctx['scenario_name']}")

        # 5b: classify
        findings = classify_findings(findings, clinical_ctx)
        for f in findings:
            cls = f.get("recist_classification", f.get("lungrads_classification", ""))
            add_log(f"  â€¢ {f['SegmentLabel']}: {f['diameter_axial_max_mm']:.1f}mm â†’ {cls}")

        # 5c: tracking
        tracking_table = build_lesion_tracking_table(patient_info["id"], accession, findings, excel_df)
        log_text = add_log("âœ… Tableau de suivi F1â†”F1 construit")
        yield "", "", log_text, None

        # 5d: RECIST
        recist_eval = build_recist_evaluation(tracking_table, findings, clinical_ctx)
        if recist_eval:
            import re as _re
            m = _re.search(r'â†’ Ã‰VALUATION : (.+)', recist_eval)
            if m:
                log_text = add_log(f"âœ… RECIST : {m.group(1)}")

        # 5e: motif
        motif = extract_exam_motif(current_clinical)

        # 5f: confidence
        progress(0.55, desc="ğŸ¯ Calcul des scores de confiance...")
        pixel_sp = 1.0
        try:
            ct_files_list = sorted([fn for fn in os.listdir(str(original_dir)) if fn.endswith(".dcm")])
            ct_ds = pydicom.dcmread(os.path.join(str(original_dir), ct_files_list[0]))
            pixel_sp = float(ct_ds.PixelSpacing[0])
        except Exception:
            pass
        has_excel = excel_df is not None
        for f in findings:
            conf = compute_confidence(f, tracking_table, pixel_sp, has_excel)
            f["confidence"] = conf
        conf_str = ", ".join(
            f"F{int(f['SegmentLabel'].replace('Finding.',''))}({f['confidence']['score']}/8)"
            for f in findings
        )
        log_text = add_log(f"âœ… Confiance : {conf_str}")
        yield "", "", log_text, None

        # 5g: VDT
        progress(0.60, desc="ğŸ“ˆ Calcul VDT...")
        vdt_results = compute_all_vdt(tracking_table, exam_info)
        vdt_text = format_vdt_text(vdt_results)

        # 5h: reasoning
        if clinical_ctx.get("scenario") == "B":
            reasoning_text = format_recist_reasoning(tracking_table, findings, clinical_ctx, recist_eval, vdt_results)
        else:
            reasoning_text = format_lungrads_reasoning(findings, tracking_table, vdt_results)

        # 5i: hounsfield
        hu_note = analyze_hounsfield(findings, exam_info)

        # 5j: audit
        audit = audit_data_completeness(patient_info, exam_info, findings, excel_df, patient_info["id"])
        audit["missing"] = [m for m in audit["missing"] if "DensitÃ©" not in m]
        audit["missing"].append(hu_note)
        log_text = add_log(f"âœ… Audit : {len(audit['missing'])} donnÃ©es manquantes identifiÃ©es")
        yield "", "", log_text, None

        # 5k-5l: tagged data + sources trace
        tagged_data = format_tagged_data(
            patient_info, exam_info, findings, tracking_table,
            recist_eval, clinical_ctx, current_clinical,
        )
        sources_trace = build_sources_trace(
            patient_info, exam_info, findings, tracking_table,
            recist_eval, clinical_ctx, current_clinical, seg_path,
        )
        for label, v in vdt_results.items():
            if v.get("vdt_days") is not None:
                sources_trace["sources"].append({
                    "data": f"VDT {label} = {v['vdt_days']}j",
                    "source": "CALC", "method": "volume_doubling_time",
                })
        sources_path = patient_dir / "sources_trace.json"
        sources_path.write_text(json.dumps(sources_trace, indent=2, ensure_ascii=False), encoding="utf-8")

        # â”€â”€ Step 6: Generate report â”€â”€
        progress(0.70, desc="ğŸ¤– GÃ©nÃ©ration du rapport via Gemini...")
        log_text = add_log("ğŸ¤– GÃ©nÃ©ration du rapport via Gemini...")
        yield "", "", log_text, None

        report = step_generate_report(
            patient_info, exam_info, findings, info_text,
            current_clinical, history_text, gemini_key, clinical_ctx,
            tracking_table, recist_eval, audit, tagged_data,
            vdt_text, reasoning_text,
        )
        n_words = len(report.split())
        log_text = add_log(f"âœ… Rapport gÃ©nÃ©rÃ© ({n_words} mots)")
        yield "", "", log_text, None

        # â”€â”€ Step 6b: Verification â”€â”€
        progress(0.80, desc="ğŸ” VÃ©rification anti-hallucination...")
        log_text = add_log("ğŸ” VÃ©rification anti-hallucination...")
        yield "", "", log_text, None

        verification = verify_report(report, findings, tracking_table, clinical_ctx, recist_eval)
        verif_path = patient_dir / "verification_report.json"
        verif_path.write_text(json.dumps(verification, indent=2, ensure_ascii=False), encoding="utf-8")

        issues = [c for c in verification["checks"] if c["status"] != "OK"]
        log_text = add_log(f"ğŸ“Š FiabilitÃ© initiale : {verification['reliability_score']} ({len(issues)} problÃ¨me(s))")

        # â”€â”€ Step 6b2: Self-correction â”€â”€
        self_correction_info = {"applied": False, "original_issues": len(issues), "corrected_issues": 0}

        if issues:
            progress(0.85, desc="ğŸ”„ Self-correction en cours...")
            log_text = add_log("ğŸ”„ Tentative de self-correction...")
            yield "", "", log_text, None

            correction_prompt = build_correction_prompt(report, issues, findings)
            if correction_prompt:
                corrected_report, corr_model = call_gemini_correction(correction_prompt, gemini_key)
                if corrected_report:
                    corrected_verification = verify_report(
                        corrected_report, findings, tracking_table, clinical_ctx, recist_eval
                    )
                    corrected_issues = [c for c in corrected_verification["checks"] if c["status"] != "OK"]
                    self_correction_info["corrected_issues"] = len(corrected_issues)

                    if len(corrected_issues) <= len(issues):
                        report = corrected_report
                        verification = corrected_verification
                        self_correction_info["applied"] = True
                        verif_path.write_text(json.dumps(verification, indent=2, ensure_ascii=False), encoding="utf-8")
                        fixed = len(issues) - len(corrected_issues)
                        log_text = add_log(f"âœ… Self-correction acceptÃ©e : {len(issues)} â†’ {len(corrected_issues)} problÃ¨mes ({fixed} corrigÃ©(s))")
                    else:
                        log_text = add_log(f"âš ï¸ Self-correction rejetÃ©e ({len(issues)} â†’ {len(corrected_issues)})")
        else:
            log_text = add_log("âœ… Aucune hallucination dÃ©tectÃ©e")
        yield "", "", log_text, None

        # Save audit trail
        audit_trail = {"self_correction": self_correction_info}
        (patient_dir / "audit_trail.json").write_text(
            json.dumps(audit_trail, indent=2, ensure_ascii=False), encoding="utf-8"
        )

        # â”€â”€ Step 6c: Quality â”€â”€
        progress(0.90, desc="ğŸ“‹ Auto-Ã©valuation qualitÃ©...")
        quality = evaluate_report_quality(report, findings, clinical_ctx, verification)
        (patient_dir / "quality_report.json").write_text(
            json.dumps(quality, indent=2, ensure_ascii=False), encoding="utf-8"
        )
        log_text = add_log(f"âœ… QualitÃ© : {quality['score']}")

        # â”€â”€ Step 7: Save â”€â”€
        progress(0.95, desc="ğŸ’¾ Sauvegarde...")
        step_output(str(patient_dir), patient_info, exam_info, findings, info_text, report, clinical_ctx)
        log_text = add_log("ğŸ’¾ Fichiers sauvegardÃ©s")
        log_text = add_log(f"\nğŸ‰ Pipeline terminÃ© avec succÃ¨s !")

        progress(1.0, desc="âœ… TerminÃ© !")

        # Build outputs
        confidence_card = _build_confidence_card(patient_dir, accession)
        chart = _build_evolution_chart(patient_dir)

        yield report, confidence_card, log_text, chart

    except Exception as e:
        error_msg = f"âŒ **Erreur** : {e}\n\n```\n{traceback.format_exc()}\n```"
        log_text = add_log(f"\nâŒ ERREUR : {e}")
        yield error_msg, "", log_text, None


# â”€â”€ History tab â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_patient_history(selection):
    """Load all exam history for a patient."""
    patient_id, _ = parse_selection(selection)
    if not patient_id or not EXCEL_PATH.exists():
        return "SÃ©lectionnez un patient.", None

    df = pd.read_excel(str(EXCEL_PATH))
    patient_rows = df[df["PatientID"] == patient_id].copy()
    if patient_rows.empty:
        return f"Aucune donnÃ©e pour {patient_id}.", None

    # Clinical context
    clinical_ctx = classify_clinical_context(patient_id, df)

    lines = [
        f"## Patient {patient_id}",
        f"**ScÃ©nario** : {clinical_ctx['scenario']} â€” {clinical_ctx['scenario_name']}",
        f"**CritÃ¨res** : {clinical_ctx['criteria']}",
        f"**Evidence** : {', '.join(clinical_ctx['evidence'])}",
        f"**Nombre d'examens** : {len(patient_rows)}",
        "",
    ]

    # Table of exams
    table_data = []
    for _, row in patient_rows.iterrows():
        acc = str(row["AccessionNumber"])
        sizes_raw = str(row.get("lesion size in mm", ""))
        sizes = [s.strip() for s in sizes_raw.strip().split("\n") if s.strip()]
        clinical = str(row.get("Clinical information data (Pseudo reports)", ""))[:100]
        has_report = (PATIENTS_DIR / acc / "rapport_radiologique.md").exists()
        status = "âœ… Rapport gÃ©nÃ©rÃ©" if has_report else "â€”"
        table_data.append({
            "Accession": acc,
            "Nb lÃ©sions": len(sizes),
            "Tailles (mm)": ", ".join(sizes[:6]),
            "Statut": status,
        })

    table_df = pd.DataFrame(table_data)

    # Evolution text
    lines.append("### Ã‰volution des lÃ©sions")
    exams = []
    for _, row in patient_rows.iterrows():
        acc = str(row["AccessionNumber"])
        sizes_raw = str(row.get("lesion size in mm", ""))
        sizes = []
        for s in sizes_raw.strip().split("\n"):
            s = s.strip()
            if s:
                try:
                    sizes.append(float(s))
                except ValueError:
                    pass
        exams.append({"accession": acc, "sizes": sizes})

    exams.sort(key=lambda e: int(e["accession"]))
    max_findings = max((len(e["sizes"]) for e in exams), default=0)

    for fi in range(max_findings):
        parts = []
        for i, e in enumerate(exams):
            if fi < len(e["sizes"]):
                parts.append(f"{e['sizes'][fi]}mm")
            else:
                parts.append("â€”")
        lines.append(f"- **F{fi+1}** : {' â†’ '.join(parts)}")

    return "\n".join(lines), table_df


# â”€â”€ About tab content â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ABOUT_TEXT = """
## UNBOXED â€” Pipeline Agentique de Radiologie

**Hackathon GE Healthcare x Centrale Lyon â€” 2026**

### Le problÃ¨me
Un radiologue analyse 50-100 dossiers/jour. En oncologie pulmonaire, comparer des nodules
sur 3-6 examens CT, calculer les variations RECIST, et rÃ©diger un rapport conforme prend
15 Ã  30 minutes par patient.

### Notre solution
Un agent IA en **12 Ã©tapes** qui automatise la chaÃ®ne complÃ¨te :

```
Orthanc PACS â†’ Download CT â†’ Segmentation AI â†’ Analyse volumÃ©trique
                                                      â†“
Excel clinique â†’ Contexte + Historique â†’ Intelligence clinique
                                                      â†“
                                        Construction du prompt
                                                      â†“
                                        LLM (Gemini) â†’ Rapport
                                                      â†“
                                        VÃ©rification anti-hallucination
                                                      â†“
                                        Self-correction automatique
                                                      â†“
                                        Auto-Ã©valuation qualitÃ© (10/10)
                                                      â†“
                                        Validation radiologue
```

### Ce qui nous diffÃ©rencie

1. **Intelligence clinique** â€” L'agent comprend *pourquoi* il fait le rapport
   (scÃ©nario A: Lung-RADS vs scÃ©nario B: RECIST 1.1)
2. **Anti-hallucination prouvÃ©e** â€” Le systÃ¨me dÃ©tecte et corrige automatiquement
   les inventions du LLM (localisations anatomiques, chiffres incorrects)
3. **VDT automatique** â€” Temps de Doublement VolumÃ©trique calculÃ© pour chaque lÃ©sion
4. **Raisonnement RECIST transparent** â€” Tous les calculs sont visibles et vÃ©rifiables
5. **Confidence scoring** â€” Le radiologue sait oÃ¹ concentrer sa relecture

### Stack technique

| Composant | Technologie |
|-----------|-------------|
| Pipeline | Python, pydicom, numpy, pandas |
| Segmentation | dcm_seg_nodules (GE Healthcare) |
| LLM | Google Gemini 2.5 Flash |
| Protocole agentique | MCP (Model Context Protocol) |
| PACS | Orthanc DICOM Server |
| Interface | Gradio |

### Ã‰thique
- L'agent ne remplace **jamais** le radiologue
- Chaque rapport porte un **avertissement IA**
- DonnÃ©es **pseudonymisÃ©es** (pas de nom rÃ©el)
- **Audit trail** complet pour traÃ§abilitÃ© mÃ©dico-lÃ©gale
"""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  GRADIO INTERFACE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

patient_choices = load_patient_choices()

with gr.Blocks(title="UNBOXED â€” Agent Radiologique") as demo:

    gr.HTML(
        """
        <div style="text-align:center; padding: 20px 0 10px 0;">
            <h1 style="margin-bottom:5px;">ğŸ¥ UNBOXED â€” Agent Radiologique Intelligent</h1>
            <p style="color:#6b7280; font-size:1.15em; margin-top:0;">
                Hackathon GE Healthcare Ã— Centrale Lyon 2026
            </p>
        </div>
        """
    )

    with gr.Tabs():
        # â”€â”€ TAB 1: Generate report â”€â”€
        with gr.TabItem("ğŸ”¬ GÃ©nÃ©rer un rapport"):
            with gr.Row():
                patient_dropdown = gr.Dropdown(
                    choices=patient_choices,
                    label="SÃ©lectionner un patient",
                    info="PatientID | AccessionNumber | Nombre d'examens | ScÃ©nario (âœ… = rÃ©sultats existants)",
                    scale=3,
                )
                with gr.Column(scale=1, min_width=200):
                    run_btn = gr.Button("ğŸš€ Lancer le pipeline", variant="primary", size="lg")
                    load_btn = gr.Button("ğŸ“‚ Voir rÃ©sultats existants", variant="secondary", size="lg")

            progress_log = gr.Textbox(
                label="ğŸ“‹ Journal d'exÃ©cution",
                lines=12,
                max_lines=25,
                interactive=False,
            )

            with gr.Row():
                with gr.Column(scale=2):
                    report_output = gr.Markdown(
                        label="ğŸ“„ Rapport radiologique",
                        value="*SÃ©lectionnez un patient et lancez le pipeline.*",
                    )
                with gr.Column(scale=1):
                    confidence_output = gr.Markdown(
                        label="ğŸ¯ Fiche de confiance",
                        value="",
                    )

            evolution_chart = gr.Plot(label="ğŸ“ˆ Ã‰volution des lÃ©sions")

            # Wire buttons
            run_btn.click(
                fn=run_full_pipeline,
                inputs=[patient_dropdown],
                outputs=[report_output, confidence_output, progress_log, evolution_chart],
            )
            load_btn.click(
                fn=load_existing_results,
                inputs=[patient_dropdown],
                outputs=[report_output, confidence_output, progress_log, evolution_chart],
            )

        # â”€â”€ TAB 2: History â”€â”€
        with gr.TabItem("ğŸ“‹ Historique patient"):
            history_dropdown = gr.Dropdown(
                choices=patient_choices,
                label="SÃ©lectionner un patient",
            )
            history_btn = gr.Button("ğŸ“Š Charger l'historique", variant="primary")

            history_text = gr.Markdown(value="*SÃ©lectionnez un patient.*")
            history_table = gr.Dataframe(
                label="Examens disponibles",
                interactive=False,
            )

            history_btn.click(
                fn=load_patient_history,
                inputs=[history_dropdown],
                outputs=[history_text, history_table],
            )

        # â”€â”€ TAB 3: About â”€â”€
        with gr.TabItem("â„¹ï¸ Ã€ propos"):
            gr.Markdown(ABOUT_TEXT)


# â”€â”€ Launch â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    demo.launch(
        share=True,
        server_name="0.0.0.0",
        server_port=7860,
        show_error=True,
        theme=gr.themes.Soft(),
    )
